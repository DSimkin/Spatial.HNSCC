# Load necessary packages
if (!requireNamespace("httr", quietly = TRUE)) {
  install.packages("httr")
}
if (!requireNamespace("jsonlite", quietly = TRUE)) {
  install.packages("jsonlite")
}
if (!requireNamespace("here", quietly = TRUE)) {
  install.packages("here")
}

library(httr)
library(jsonlite)
library(here)

options(timeout = 1200)

# ID for analysis results collection
collection_id <- "7569888"
# YOU NEED TO GENERATE Figshare (OAuth) TOKEN: After creating a figshare account go to  user menu  -->  Applications  -->  Create Personal Token
# EITHER REPLACE <Figshare_TOKEN> WITH YOUR TOKEN.
# OR ALTERNATIVLEY ADD IT TO YOUR .Renviron FILES like this:
# In bash: touch ~/.Renviron
# Insert the token generated by Figshare to the .Renviron file as such:  FIGSHARE_TOKEN=your_figshare_token_here
# If you stored the token in .Renviron file DO NOT change next code line  (token <- "<Figshare_TOKEN>")
token <- "<Figshare_TOKEN>"
if (token == "<Figshare_TOKEN>") {
  token <- Sys.getenv("FIGSHARE_TOKEN")
}
if (token == "") {
  stop("Figshare token not found. Please check your .Rprofile.")
}

# API endpoint for the articles in the collection
articles_url <- paste0("https://api.figshare.com/v2/collections/", collection_id, "/articles")

# Directory to store the first batch of downloaded files
output_dir <- here("results")
if (!dir.exists(output_dir)) {
  dir.create(output_dir)
}

# Fetch articles metadata
response <- httr::GET(articles_url, add_headers(Authorization = paste("token", token)))

if (response$status_code == 200) {
  # Parse the response to extract articles
  articles_data <- jsonlite::fromJSON(httr::content(response, "text"))
  
  # Loop through each article to fetch and download its files
  for (article_id in articles_data$id) {
    # Fetch article metadata
    article_url <- paste0("https://api.figshare.com/v2/articles/", article_id)
    article_response <- httr::GET(article_url, add_headers(Authorization = paste("token", token)))
    
    if (article_response$status_code == 200) {
      article_data <- jsonlite::fromJSON(httr::content(article_response, "text"))
      
      # Extract article title for subdirectory creation
      article_title <- gsub("[^A-Za-z0-9_]", "_", article_data$title)
      article_dir <- file.path(output_dir, article_title)
      if (!dir.exists(article_dir)) {
        dir.create(article_dir)
      }
      
      # Download each file in the article
      for (i in 1:nrow(article_data$files)) {
        file_url <- article_data$files$download_url[[i]]
        file_name <- article_data$files$name[[i]]
        download_path <- file.path(article_dir, file_name)
        
        cat("Downloading:", file_name, "from", file_url, "\n")
        download.file(file_url, destfile = download_path, mode = "wb")
      }
    } else {
      cat("Failed to fetch article metadata for ID:", article_id, "\n")
    }
  }
  cat("First batch of files downloaded successfully!\nMoving to the second batch of files\n")
} else {
  cat("Error fetching articles. Status code:", response$status_code, "\n")
}


# ID for analysis results collection
article_id <- "27967107"

# API endpoint for the articles in the collection
article_url <- paste0("https://api.figshare.com/v2/articles/", article_id)

# Fetch article metadata
article_response <- httr::GET(article_url, add_headers(Authorization = paste("token", token)))

# Directory to store the second batch of downloaded files
output_dir <- here("aux_data")
if (!dir.exists(output_dir)) {
  dir.create(output_dir)
}

if (article_response$status_code == 200) {
  article_data <- jsonlite::fromJSON(httr::content(article_response, "text"))
  
  # Download each file in the article
  for (i in 1:nrow(article_data$files)) {
    file_url <- article_data$files$download_url[[i]]
    file_name <- article_data$files$name[[i]]
    download_path <- file.path(output_dir, file_name)
    
    cat("Downloading:", file_name, "from", file_url, "\n")
    download.file(file_url, destfile = download_path, mode = "wb")
  }
  cat("Second batch of files downloaded successfully!\nDone!\n")
} else {
  cat("Failed to fetch article metadata for ID:", article_id, "\n")
}


